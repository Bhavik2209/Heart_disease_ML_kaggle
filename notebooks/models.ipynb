{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVcQjk_9MuhH",
        "outputId": "86f33c29-6659-4c8d-ccb9-c58b98ea4d34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.18.4)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (26.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoSI8T3GMwCq",
        "outputId": "362c971e-740b-44fb-e2b0-407e3904cc23"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.10-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas<4.0,>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<4.0,>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<4.0,>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<4.0,>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.4)\n",
            "Downloading catboost-1.2.10-cp312-cp312-manylinux2014_x86_64.whl (97.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NPBXn9TALrx_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"SECTION 1: DATA LOADING & PREPROCESSING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "df    = pd.read_csv(\"/content/train.csv\")\n",
        "test  = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# ── Target encoding ──────────────────────────────────────────────────────────\n",
        "df[\"Heart Disease\"] = df[\"Heart Disease\"].map({\"Absence\": 0, \"Presence\": 1})\n",
        "\n",
        "# ── Drop rows where target is NaN (1 row) ────────────────────────────────────\n",
        "df.dropna(subset=[\"Heart Disease\"], inplace=True)\n",
        "df[\"Heart Disease\"] = df[\"Heart Disease\"].astype(int)\n",
        "\n",
        "# ── Drop ID column ────────────────────────────────────────────────────────────\n",
        "df.drop(columns=[\"id\"], inplace=True)\n",
        "\n",
        "print(f\"Train shape : {df.shape}\")\n",
        "print(f\"Test  shape : {test.shape}\")\n",
        "print(f\"Target distribution:\\n{df['Heart Disease'].value_counts()}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPlaoVTGL33t",
        "outputId": "32fe124b-63c8-4995-f4da-7472188e6e84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 1: DATA LOADING & PREPROCESSING\n",
            "======================================================================\n",
            "Train shape : (630000, 14)\n",
            "Test  shape : (270000, 14)\n",
            "Target distribution:\n",
            "Heart Disease\n",
            "0    347546\n",
            "1    282454\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"SECTION 2: FEATURE GROUPS & PREPROCESSORS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ── Feature groups (based on EDA findings) ───────────────────────────────────\n",
        "numeric_features = [\n",
        "    \"Age\", \"BP\", \"Cholesterol\", \"Max HR\", \"ST depression\"\n",
        "]\n",
        "\n",
        "binary_features = [\n",
        "    \"Sex\", \"FBS over 120\", \"Exercise angina\"\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    \"Chest pain type\",   # nominal — 4 unordered categories\n",
        "    \"EKG results\",       # nominal — values 0/1/2 are labels, not a scale\n",
        "    \"Slope of ST\",       # nominal — non-linear jump between levels (EDA)\n",
        "    \"Thallium\"           # nominal — non-consecutive codes 3/6/7\n",
        "]\n",
        "\n",
        "ordinal_features = [\n",
        "    \"Number of vessels fluro\"   # ordinal — monotonic risk increase 0→3\n",
        "]\n",
        "\n",
        "TARGET = \"Heart Disease\"\n",
        "\n",
        "# ── Preprocessor for tree-based models (no scaling needed) ───────────────────\n",
        "preprocessor_tree = ColumnTransformer(transformers=[\n",
        "    (\"num\", \"passthrough\",                                  numeric_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"),         categorical_features),\n",
        "    (\"bin\", \"passthrough\",                                  binary_features),\n",
        "    (\"ord\", \"passthrough\",                                  ordinal_features),\n",
        "])\n",
        "\n",
        "# ── Preprocessor for linear models (StandardScaler + OneHot) ─────────────────\n",
        "preprocessor_linear = ColumnTransformer(transformers=[\n",
        "    (\"num\", StandardScaler(),                               numeric_features),\n",
        "    (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), categorical_features),\n",
        "    (\"bin\", \"passthrough\",                                  binary_features),\n",
        "    (\"ord\", \"passthrough\",                                  ordinal_features),\n",
        "])\n",
        "\n",
        "print(\"Feature groups defined.\")\n",
        "print(f\"  Numeric     : {len(numeric_features)} features\")\n",
        "print(f\"  Categorical : {len(categorical_features)} features (OneHot encoded)\")\n",
        "print(f\"  Binary      : {len(binary_features)} features (pass-through)\")\n",
        "print(f\"  Ordinal     : {len(ordinal_features)} feature  (pass-through)\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFYElIKJL308",
        "outputId": "487d8e77-b3b5-4f53-9136-6975ce7bbcfc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 2: FEATURE GROUPS & PREPROCESSORS\n",
            "======================================================================\n",
            "Feature groups defined.\n",
            "  Numeric     : 5 features\n",
            "  Categorical : 4 features (OneHot encoded)\n",
            "  Binary      : 3 features (pass-through)\n",
            "  Ordinal     : 1 feature  (pass-through)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"SECTION 3: CROSS-VALIDATION SETUP\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "X_test    = test.drop(columns=[\"id\"])\n",
        "test_ids  = test[\"id\"]\n",
        "\n",
        "SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"Strategy : 5-Fold Stratified K-Fold (maintains class ratio per fold)\")\n",
        "print(f\"Train size: {len(X):,}  |  Positive rate: {y.mean():.4f}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHYmxCFVL3yO",
        "outputId": "555ac2ab-d80e-403f-be01-cb2763ec8964"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 3: CROSS-VALIDATION SETUP\n",
            "======================================================================\n",
            "Strategy : 5-Fold Stratified K-Fold (maintains class ratio per fold)\n",
            "Train size: 630,000  |  Positive rate: 0.4483\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zIdotxO0Nscy",
        "outputId": "aac70720-609a-4939-a54b-39f632cfd7e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.9.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-skinny==3.9.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.9.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting mlflow-tracing==3.9.0 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.9.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow)\n",
            "  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.18.4)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting huey<3,>=2.5.4 (from mlflow)\n",
            "  Downloading huey-2.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Collecting skops<1 (from mlflow)\n",
            "  Downloading skops-0.13.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.46)\n",
            "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.9.0->mlflow)\n",
            "  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.2)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.9.0->mlflow)\n",
            "  Downloading databricks_sdk-0.90.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.129.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (3.1.46)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (8.7.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.38.0)\n",
            "Collecting packaging<26 (from mlflow-skinny==3.9.0->mlflow)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (5.29.6)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.5.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.9.0->mlflow) (0.40.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.5)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.3.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: prettytable>=3.9 in /usr/local/lib/python3.12/dist-packages (from skops<1->mlflow) (3.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (3.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (2.47.0)\n",
            "Requirement already satisfied: starlette<1.0.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.9.0->mlflow) (0.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.9.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.9.0->mlflow) (0.59b0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable>=3.9->skops<1->mlflow) (0.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.9.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.9.0->mlflow) (2026.1.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.9.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.9.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<1.0.0,>=0.40.0->fastapi<1->mlflow-skinny==3.9.0->mlflow) (4.12.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.9.0->mlflow) (0.6.2)\n",
            "Downloading mlflow-3.9.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.9.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huey-2.6.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading skops-0.13.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
            "Downloading databricks_sdk-0.90.0-py3-none-any.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huey, packaging, graphql-core, cachetools, gunicorn, graphql-relay, docker, skops, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 26.0\n",
            "    Uninstalling packaging-26.0:\n",
            "      Successfully uninstalled packaging-26.0\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 7.0.1\n",
            "    Uninstalling cachetools-7.0.1:\n",
            "      Successfully uninstalled cachetools-7.0.1\n",
            "Successfully installed Flask-CORS-6.0.2 cachetools-6.2.6 databricks-sdk-0.90.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.6.0 mlflow-3.9.0 mlflow-skinny-3.9.0 mlflow-tracing-3.9.0 packaging-25.0 skops-0.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              },
              "id": "35d87e64ed394dd3b76d044282699320"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow"
      ],
      "metadata": {
        "id": "dIzNV7PmNubq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "zsLtXenZN_Hz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"SECTION 4: MLFLOW & NPY SETUP\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "EXPERIMENT_NAME = \"Heart_Disease_Prediction\"\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "\n",
        "# Change to /content/drive/MyDrive/npy_results to persist across Colab sessions\n",
        "NPY_DIR = \"/content/npy_results\"\n",
        "os.makedirs(NPY_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"MLflow experiment : {EXPERIMENT_NAME}\")\n",
        "print(f\"NPY save directory: {NPY_DIR}\\n\")\n",
        "\n",
        "\n",
        "def save_npy(array: np.ndarray, name: str) -> str:\n",
        "    \"\"\"Save array as .npy file and return its path for MLflow logging.\"\"\"\n",
        "    path = os.path.join(NPY_DIR, f\"{name}.npy\")\n",
        "    np.save(path, array)\n",
        "    print(f\"    [NPY] Saved → {name}.npy  shape={array.shape}\")\n",
        "    return path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG2GM_X1NqAD",
        "outputId": "6771d81d-1a28-4cb6-cfe8-833bc7c1c59e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 4: MLFLOW & NPY SETUP\n",
            "======================================================================\n",
            "MLflow experiment : Heart_Disease_Prediction\n",
            "NPY save directory: /content/npy_results\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 5 — MODEL 1: LightGBM  (Optuna-Tuned)\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"SECTION 5: MODEL 1 — LightGBM Classifier\")\n",
        "print(\"=\" * 70)\n",
        "print(\"  Hyperparameters: Optuna search, 30 trials, best Trial 0\")\n",
        "print(\"  Metric: ROC-AUC  |  CV: 5-Fold OOF\\n\")\n",
        "\n",
        "lgb_params = dict(\n",
        "    n_estimators      = 1661,\n",
        "    learning_rate     = 0.012503626241860565,\n",
        "    num_leaves        = 31,\n",
        "    max_depth         = 6,\n",
        "    min_child_samples = 43,\n",
        "    subsample         = 0.643072395692159,\n",
        "    colsample_bytree  = 0.7211161958467457,\n",
        "    reg_alpha         = 1.0504857541588257,\n",
        "    reg_lambda        = 0.11946226125639381,\n",
        "    random_state      = 42,\n",
        "    n_jobs            = -1,\n",
        "    verbosity         = -1,  # GPU acceleration (Colab T4/A100)\n",
        "    gpu_platform_id   = 0,\n",
        "    gpu_device_id     = 0,\n",
        ")\n",
        "\n",
        "with mlflow.start_run(run_name=\"LightGBM\") as run:\n",
        "    lgb_run_id = run.info.run_id\n",
        "    mlflow.log_params(lgb_params)\n",
        "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
        "    mlflow.log_param(\"cv_folds\",   5)\n",
        "\n",
        "    lgb_pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor_tree),\n",
        "        (\"model\",        LGBMClassifier(**lgb_params)),\n",
        "    ])\n",
        "\n",
        "    oof_lgb = np.zeros(len(X))\n",
        "    for fold, (tr_idx, val_idx) in enumerate(SKF.split(X, y)):\n",
        "        X_tr, X_val = X.iloc[tr_idx],  X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx],  y.iloc[val_idx]\n",
        "        lgb_pipeline.fit(X_tr, y_tr)\n",
        "        oof_lgb[val_idx] = lgb_pipeline.predict_proba(X_val)[:, 1]\n",
        "        fold_auc = roc_auc_score(y_val, oof_lgb[val_idx])\n",
        "        mlflow.log_metric(f\"fold_{fold+1}_auc\", fold_auc)\n",
        "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
        "\n",
        "    lgb_oof_auc = roc_auc_score(y, oof_lgb)\n",
        "    mlflow.log_metric(\"oof_roc_auc\", lgb_oof_auc)\n",
        "    print(f\"\\n  LightGBM OOF ROC-AUC : {lgb_oof_auc:.5f}\")\n",
        "\n",
        "    # Full refit on all training data\n",
        "    lgb_pipeline.fit(X, y)\n",
        "    lgb_test_preds = lgb_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Save .npy immediately after run — safe against Colab disconnects\n",
        "    mlflow.log_artifact(save_npy(oof_lgb,        \"oof_lgb\"),        artifact_path=\"npy\")\n",
        "    mlflow.log_artifact(save_npy(lgb_test_preds, \"test_preds_lgb\"), artifact_path=\"npy\")\n",
        "    print(f\"  MLflow Run ID : {lgb_run_id}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTSGvY_qL3vk",
        "outputId": "db340435-ba82-4d46-f225-63b0b47e41b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 5: MODEL 1 — LightGBM Classifier\n",
            "======================================================================\n",
            "  Hyperparameters: Optuna search, 30 trials, best Trial 0\n",
            "  Metric: ROC-AUC  |  CV: 5-Fold OOF\n",
            "\n",
            "  Fold 1 AUC: 0.95563\n",
            "  Fold 2 AUC: 0.95459\n",
            "  Fold 3 AUC: 0.95539\n",
            "  Fold 4 AUC: 0.95495\n",
            "  Fold 5 AUC: 0.95579\n",
            "\n",
            "  LightGBM OOF ROC-AUC : 0.95527\n",
            "    [NPY] Saved → oof_lgb.npy  shape=(630000,)\n",
            "    [NPY] Saved → test_preds_lgb.npy  shape=(270000,)\n",
            "  MLflow Run ID : 10ec9ac61f3b484c92953673a40cb830\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 6 — MODEL 2: XGBoost  (Optuna-Tuned)\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"SECTION 6: MODEL 2 — XGBoost Classifier\")\n",
        "print(\"=\" * 70)\n",
        "print(\"  Hyperparameters: Optuna search, best Trial 0\")\n",
        "print(\"  Metric: ROC-AUC  |  CV: 5-Fold OOF\\n\")\n",
        "\n",
        "xgb_params = dict(\n",
        "    n_estimators     = 972,\n",
        "    learning_rate    = 0.08233334476657686,\n",
        "    max_depth        = 3,\n",
        "    subsample        = 0.6967792979720865,\n",
        "    colsample_bytree = 0.7773146292728021,\n",
        "    reg_alpha        = 1.911349598671315,\n",
        "    reg_lambda       = 0.6194119678307304,\n",
        "    tree_method      = \"hist\",\n",
        "    eval_metric      = \"logloss\",\n",
        "    device           = \"cuda\",          # GPU acceleration (Colab T4/A100)\n",
        "    random_state     = 42,\n",
        "    n_jobs           = -1,\n",
        ")\n",
        "\n",
        "with mlflow.start_run(run_name=\"XGBoost\") as run:\n",
        "    xgb_run_id = run.info.run_id\n",
        "    mlflow.log_params(xgb_params)\n",
        "    mlflow.log_param(\"model_type\", \"XGBoost\")\n",
        "    mlflow.log_param(\"cv_folds\",   5)\n",
        "\n",
        "    xgb_pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor_tree),\n",
        "        (\"model\",        XGBClassifier(**xgb_params)),\n",
        "    ])\n",
        "\n",
        "    oof_xgb = np.zeros(len(X))\n",
        "    for fold, (tr_idx, val_idx) in enumerate(SKF.split(X, y)):\n",
        "        X_tr, X_val = X.iloc[tr_idx],  X.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx],  y.iloc[val_idx]\n",
        "        xgb_pipeline.fit(X_tr, y_tr)\n",
        "        oof_xgb[val_idx] = xgb_pipeline.predict_proba(X_val)[:, 1]\n",
        "        fold_auc = roc_auc_score(y_val, oof_xgb[val_idx])\n",
        "        mlflow.log_metric(f\"fold_{fold+1}_auc\", fold_auc)\n",
        "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
        "\n",
        "    xgb_oof_auc = roc_auc_score(y, oof_xgb)\n",
        "    mlflow.log_metric(\"oof_roc_auc\", xgb_oof_auc)\n",
        "    print(f\"\\n  XGBoost OOF ROC-AUC : {xgb_oof_auc:.5f}\")\n",
        "\n",
        "    # Full refit\n",
        "    xgb_pipeline.fit(X, y)\n",
        "    xgb_test_preds = xgb_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Save .npy immediately after run\n",
        "    mlflow.log_artifact(save_npy(oof_xgb,        \"oof_xgb\"),        artifact_path=\"npy\")\n",
        "    mlflow.log_artifact(save_npy(xgb_test_preds, \"test_preds_xgb\"), artifact_path=\"npy\")\n",
        "    print(f\"  MLflow Run ID : {xgb_run_id}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulGA6NQ5L3s0",
        "outputId": "5ef66dde-4ce5-417d-9623-add7dffd4ef6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 6: MODEL 2 — XGBoost Classifier\n",
            "======================================================================\n",
            "  Hyperparameters: Optuna search, best Trial 0\n",
            "  Metric: ROC-AUC  |  CV: 5-Fold OOF\n",
            "\n",
            "  Fold 1 AUC: 0.95585\n",
            "  Fold 2 AUC: 0.95480\n",
            "  Fold 3 AUC: 0.95553\n",
            "  Fold 4 AUC: 0.95516\n",
            "  Fold 5 AUC: 0.95595\n",
            "\n",
            "  XGBoost OOF ROC-AUC : 0.95545\n",
            "    [NPY] Saved → oof_xgb.npy  shape=(630000,)\n",
            "    [NPY] Saved → test_preds_xgb.npy  shape=(270000,)\n",
            "  MLflow Run ID : 535c855619fe48bc9e5b4f2beb683cb6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 7 — MODEL 3: CatBoost  (Optuna-Tuned)\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"SECTION 7: MODEL 3 — CatBoost Classifier\")\n",
        "print(\"=\" * 70)\n",
        "print(\"  Hyperparameters: Optuna search, best Trial 3\")\n",
        "print(\"  Handles categoricals natively via Pool API — no OneHot needed\")\n",
        "print(\"  Metric: ROC-AUC  |  CV: 5-Fold OOF\\n\")\n",
        "\n",
        "# CatBoost Pool API requires categorical columns as strings\n",
        "cat_cols_cb = [\n",
        "    \"Sex\", \"Chest pain type\", \"FBS over 120\", \"EKG results\",\n",
        "    \"Exercise angina\", \"Slope of ST\", \"Number of vessels fluro\", \"Thallium\"\n",
        "]\n",
        "\n",
        "def prepare_catboost(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    data = data.copy()\n",
        "    for col in cat_cols_cb:\n",
        "        data[col] = data[col].astype(str)\n",
        "    return data\n",
        "\n",
        "X_cb      = prepare_catboost(X)\n",
        "X_test_cb = prepare_catboost(X_test)\n",
        "\n",
        "cat_params = dict(\n",
        "    iterations          = 2443,\n",
        "    learning_rate       = 0.028617286398439353,\n",
        "    depth               = 6,\n",
        "    l2_leaf_reg         = 3.5313325975665264,\n",
        "    bagging_temperature = 0.5274409717782269,\n",
        "    random_strength     = 0.03843459373261249,\n",
        "          # GPU acceleration (Colab T4/A100)\n",
        "    devices             = \"0\",\n",
        "    random_seed         = 42,\n",
        "    verbose             = 0,\n",
        ")\n",
        "\n",
        "with mlflow.start_run(run_name=\"CatBoost\") as run:\n",
        "    cat_run_id = run.info.run_id\n",
        "    mlflow.log_params(cat_params)\n",
        "    mlflow.log_param(\"model_type\",   \"CatBoost\")\n",
        "    mlflow.log_param(\"cv_folds\",     5)\n",
        "    mlflow.log_param(\"cat_features\", str(cat_cols_cb))\n",
        "\n",
        "    oof_cat = np.zeros(len(X_cb))\n",
        "    for fold, (tr_idx, val_idx) in enumerate(SKF.split(X_cb, y)):\n",
        "        X_tr, X_val = X_cb.iloc[tr_idx],  X_cb.iloc[val_idx]\n",
        "        y_tr, y_val = y.iloc[tr_idx],     y.iloc[val_idx]\n",
        "\n",
        "        train_pool = Pool(X_tr,  y_tr,  cat_features=cat_cols_cb)\n",
        "        val_pool   = Pool(X_val, y_val, cat_features=cat_cols_cb)\n",
        "\n",
        "        fold_model = CatBoostClassifier(**cat_params)\n",
        "        fold_model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=200)\n",
        "        oof_cat[val_idx] = fold_model.predict_proba(val_pool)[:, 1]\n",
        "        fold_auc = roc_auc_score(y_val, oof_cat[val_idx])\n",
        "        mlflow.log_metric(f\"fold_{fold+1}_auc\", fold_auc)\n",
        "        print(f\"  Fold {fold+1} AUC: {fold_auc:.5f}\")\n",
        "\n",
        "    cat_oof_auc = roc_auc_score(y, oof_cat)\n",
        "    mlflow.log_metric(\"oof_roc_auc\", cat_oof_auc)\n",
        "    print(f\"\\n  CatBoost OOF ROC-AUC : {cat_oof_auc:.5f}\")\n",
        "\n",
        "    # Full refit\n",
        "    full_pool      = Pool(X_cb,      y,  cat_features=cat_cols_cb)\n",
        "    test_pool      = Pool(X_test_cb,     cat_features=cat_cols_cb)\n",
        "    cat_model_full = CatBoostClassifier(**cat_params)\n",
        "    cat_model_full.fit(full_pool)\n",
        "    cat_test_preds = cat_model_full.predict_proba(test_pool)[:, 1]\n",
        "\n",
        "    # Save .npy immediately after run\n",
        "    mlflow.log_artifact(save_npy(oof_cat,        \"oof_cat\"),        artifact_path=\"npy\")\n",
        "    mlflow.log_artifact(save_npy(cat_test_preds, \"test_preds_cat\"), artifact_path=\"npy\")\n",
        "    print(f\"  MLflow Run ID : {cat_run_id}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "pxjW4jpiL3qM",
        "outputId": "cee0f8a2-8970-4940-f711-ef6c461b076e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 7: MODEL 3 — CatBoost Classifier\n",
            "======================================================================\n",
            "  Hyperparameters: Optuna search, best Trial 3\n",
            "  Handles categoricals natively via Pool API — no OneHot needed\n",
            "  Metric: ROC-AUC  |  CV: 5-Fold OOF\n",
            "\n",
            "  Fold 1 AUC: 0.95582\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1318657972.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mfold_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcat_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mfold_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moof_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mfold_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5545\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5547\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5548\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5549\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2715\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Training plots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2716\u001b[0;31m                 self._train(\n\u001b[0m\u001b[1;32m   2717\u001b[0m                     \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2718\u001b[0m                     \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1824\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1825\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 8 — INDIVIDUAL MODEL COMPARISON\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"SECTION 8: INDIVIDUAL MODEL COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "model_summary = pd.DataFrame({\n",
        "    \"Model\"       : [\"LightGBM\", \"XGBoost\", ],\n",
        "    \"OOF ROC-AUC\" : [lgb_oof_auc, xgb_oof_auc, ],\n",
        "}).sort_values(\"OOF ROC-AUC\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(model_summary.to_string(index=False))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtcKUj8cL3nl",
        "outputId": "f4aa197d-ed6d-4a0a-be00-8e82da60a727"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 8: INDIVIDUAL MODEL COMPARISON\n",
            "======================================================================\n",
            "   Model  OOF ROC-AUC\n",
            " XGBoost     0.955455\n",
            "LightGBM     0.955269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 9 — BLENDING: WEIGHTED AVERAGE ENSEMBLE\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"SECTION 9: BLENDING — Weighted Average Ensemble (LGB + XGB + CAT)\")\n",
        "print(\"=\" * 70)\n",
        "print(\"  Sweep all weight combos (step 0.1), pick best OOF AUC\\n\")\n",
        "\n",
        "best_blend_auc     = 0.0\n",
        "best_blend_weights = (0.33, 0.33, 0.34)\n",
        "\n",
        "for w_lgb in np.arange(0.1, 0.7, 0.1):\n",
        "    for w_xgb in np.arange(0.1, 0.7, 0.1):\n",
        "\n",
        "        blend = w_lgb * oof_lgb + w_xgb * oof_xgb\n",
        "        auc   = roc_auc_score(y, blend)\n",
        "        if auc > best_blend_auc:\n",
        "            best_blend_auc     = auc\n",
        "            best_blend_weights = (w_lgb, w_xgb)\n",
        "\n",
        "w_lgb, w_xgb = best_blend_weights\n",
        "blend_oof_preds  = w_lgb * oof_lgb        + w_xgb * oof_xgb\n",
        "blend_test_preds = w_lgb * lgb_test_preds + w_xgb * xgb_test_preds\n",
        "\n",
        "print(f\"  Best weights → LGB: {w_lgb:.1f} | XGB: {w_xgb:.1f} \")\n",
        "print(f\"  Blended OOF ROC-AUC: {best_blend_auc:.5f}\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"Blend_LGB_XGB\") as run:\n",
        "    blend_run_id = run.info.run_id\n",
        "    mlflow.log_param(\"model_type\", \"WeightedBlend\")\n",
        "    mlflow.log_param(\"weight_lgb\", round(float(w_lgb), 2))\n",
        "    mlflow.log_param(\"weight_xgb\", round(float(w_xgb), 2))\n",
        "    mlflow.log_metric(\"oof_roc_auc\", best_blend_auc)\n",
        "\n",
        "    # Save .npy immediately after run\n",
        "    mlflow.log_artifact(save_npy(blend_oof_preds,  \"oof_blend\"),        artifact_path=\"npy\")\n",
        "    mlflow.log_artifact(save_npy(blend_test_preds, \"test_preds_blend\"), artifact_path=\"npy\")\n",
        "    print(f\"  MLflow Run ID : {blend_run_id}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHahZa0QL3lF",
        "outputId": "a1c9a695-dfa5-4b3e-9f79-81657684f477"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 9: BLENDING — Weighted Average Ensemble (LGB + XGB + CAT)\n",
            "======================================================================\n",
            "  Sweep all weight combos (step 0.1), pick best OOF AUC\n",
            "\n",
            "  Best weights → LGB: 0.1 | XGB: 0.5 \n",
            "  Blended OOF ROC-AUC: 0.95546\n",
            "    [NPY] Saved → oof_blend.npy  shape=(630000,)\n",
            "    [NPY] Saved → test_preds_blend.npy  shape=(270000,)\n",
            "  MLflow Run ID : 5446fd3dbd5d432487235c5785914cfb\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 10 — STACKING: META-LEARNER ENSEMBLE\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"SECTION 10: STACKING ENSEMBLE — HistGradientBoosting Meta-Learner\")\n",
        "print(\"=\" * 70)\n",
        "print(\"  Base learners : LightGBM · XGBoost · CatBoost OOF predictions\")\n",
        "print(\"  Meta-learner  : HistGradientBoostingClassifier\")\n",
        "print(\"  No leakage    : meta-learner trained only on OOF predictions\\n\")\n",
        "\n",
        "stacked_train = np.column_stack([oof_lgb,        oof_xgb])\n",
        "stacked_test  = np.column_stack([lgb_test_preds, xgb_test_preds])\n",
        "\n",
        "meta_params = dict(max_depth=3, learning_rate=0.05, max_iter=300, random_state=42)\n",
        "meta_model  = HistGradientBoostingClassifier(**meta_params)\n",
        "meta_model.fit(stacked_train, y)\n",
        "\n",
        "stacked_oof_preds  = meta_model.predict_proba(stacked_train)[:, 1]\n",
        "stacked_oof_auc    = roc_auc_score(y, stacked_oof_preds)\n",
        "stacked_test_preds = meta_model.predict_proba(stacked_test)[:, 1]\n",
        "\n",
        "print(f\"  Stacked OOF ROC-AUC : {stacked_oof_auc:.5f}\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"Stacking_HistGB_Meta\") as run:\n",
        "    stack_run_id = run.info.run_id\n",
        "    mlflow.log_param(\"model_type\",    \"StackingEnsemble\")\n",
        "    mlflow.log_param(\"meta_learner\",  \"HistGradientBoostingClassifier\")\n",
        "    mlflow.log_param(\"base_learners\", \"LightGBM, XGBoost\")\n",
        "    mlflow.log_params({f\"meta_{k}\": v for k, v in meta_params.items()})\n",
        "    mlflow.log_metric(\"oof_roc_auc\",  stacked_oof_auc)\n",
        "\n",
        "    # Save .npy immediately after run\n",
        "    mlflow.log_artifact(save_npy(stacked_oof_preds,  \"oof_stacked\"),        artifact_path=\"npy\")\n",
        "    mlflow.log_artifact(save_npy(stacked_test_preds, \"test_preds_stacked\"), artifact_path=\"npy\")\n",
        "    print(f\"  MLflow Run ID : {stack_run_id}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW9oNyaPL3ik",
        "outputId": "e37285f1-54c0-452d-88f3-203bf3cfcd33"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 10: STACKING ENSEMBLE — HistGradientBoosting Meta-Learner\n",
            "======================================================================\n",
            "  Base learners : LightGBM · XGBoost · CatBoost OOF predictions\n",
            "  Meta-learner  : HistGradientBoostingClassifier\n",
            "  No leakage    : meta-learner trained only on OOF predictions\n",
            "\n",
            "  Stacked OOF ROC-AUC : 0.95551\n",
            "    [NPY] Saved → oof_stacked.npy  shape=(630000,)\n",
            "    [NPY] Saved → test_preds_stacked.npy  shape=(270000,)\n",
            "  MLflow Run ID : 4a5a151107354381890b7a5f582a8c4a\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 11 — FINAL RESULTS SUMMARY\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"SECTION 11: FINAL RESULTS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    \"Approach\"    : [\"LightGBM\", \"XGBoost\",\n",
        "                     \"Blend (LGB+XGB+CAT)\", \"Stacking Ensemble\"],\n",
        "    \"OOF ROC-AUC\" : [lgb_oof_auc, xgb_oof_auc,\n",
        "                     best_blend_auc, stacked_oof_auc],\n",
        "    \"MLflow Run\"  : [lgb_run_id[:8],   xgb_run_id[:8],\n",
        "                     blend_run_id[:8], stack_run_id[:8]],\n",
        "}).sort_values(\"OOF ROC-AUC\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "results_df[\"OOF ROC-AUC\"] = results_df[\"OOF ROC-AUC\"].map(\"{:.5f}\".format)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "best_row = results_df.iloc[0]\n",
        "print(f\"\\n  ✓ Best approach : {best_row['Approach']}  (OOF AUC = {best_row['OOF ROC-AUC']})\")\n",
        "\n",
        "# List all saved .npy files with shapes\n",
        "print(f\"\\nAll .npy files saved in: {NPY_DIR}\")\n",
        "print(\"-\" * 50)\n",
        "for fname in sorted(os.listdir(NPY_DIR)):\n",
        "    if fname.endswith(\".npy\"):\n",
        "        arr = np.load(os.path.join(NPY_DIR, fname))\n",
        "        print(f\"  {fname:<35} shape={arr.shape}  dtype={arr.dtype}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EPRIdiBOd31",
        "outputId": "5e41ef3f-776c-4373-c783-f24be1187494"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SECTION 11: FINAL RESULTS SUMMARY\n",
            "======================================================================\n",
            "           Approach OOF ROC-AUC MLflow Run\n",
            "  Stacking Ensemble     0.95551   4a5a1511\n",
            "Blend (LGB+XGB+CAT)     0.95546   5446fd3d\n",
            "            XGBoost     0.95545   535c8556\n",
            "           LightGBM     0.95527   10ec9ac6\n",
            "\n",
            "  ✓ Best approach : Stacking Ensemble  (OOF AUC = 0.95551)\n",
            "\n",
            "All .npy files saved in: /content/npy_results\n",
            "--------------------------------------------------\n",
            "  oof_blend.npy                       shape=(630000,)  dtype=float64\n",
            "  oof_lgb.npy                         shape=(630000,)  dtype=float64\n",
            "  oof_stacked.npy                     shape=(630000,)  dtype=float64\n",
            "  oof_xgb.npy                         shape=(630000,)  dtype=float64\n",
            "  test_preds_blend.npy                shape=(270000,)  dtype=float64\n",
            "  test_preds_lgb.npy                  shape=(270000,)  dtype=float64\n",
            "  test_preds_stacked.npy              shape=(270000,)  dtype=float64\n",
            "  test_preds_xgb.npy                  shape=(270000,)  dtype=float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SECTION 12 — SUBMISSION FILES\n",
        "# =============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SECTION 12: GENERATING SUBMISSION FILES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def save_submission(preds: np.ndarray, ids: pd.Series, filename: str) -> None:\n",
        "    pd.DataFrame({\"id\": ids, \"Heart Disease\": preds}).to_csv(filename, index=False)\n",
        "    print(f\"  Saved: {filename}  ({len(ids):,} rows)\")\n",
        "\n",
        "save_submission(lgb_test_preds,     test_ids, \"submission_lightgbm.csv\")\n",
        "save_submission(xgb_test_preds,     test_ids, \"submission_xgboost.csv\")\n",
        "save_submission(blend_test_preds,   test_ids, \"submission_blend.csv\")\n",
        "save_submission(stacked_test_preds, test_ids, \"submission_stacked.csv\")\n",
        "\n",
        "print(\"\\nAll submissions generated successfully.\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "texQyMW3OkB4",
        "outputId": "62017199-456d-44e0-d4d4-beee9efc4d1a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SECTION 12: GENERATING SUBMISSION FILES\n",
            "======================================================================\n",
            "  Saved: submission_lightgbm.csv  (270,000 rows)\n",
            "  Saved: submission_xgboost.csv  (270,000 rows)\n",
            "  Saved: submission_blend.csv  (270,000 rows)\n",
            "  Saved: submission_stacked.csv  (270,000 rows)\n",
            "\n",
            "All submissions generated successfully.\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a zip file from folder you want to download\n",
        "!zip -r /content/file.zip /content/mlruns\n",
        "\n",
        "# download file recently created\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "E5FUMvx2W7Fq",
        "outputId": "afed1ce7-a6c1-4afc-d5e0-4fcd46733d52"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/mlruns/ (stored 0%)\n",
            "  adding: content/mlruns/1/ (stored 0%)\n",
            "  adding: content/mlruns/1/535c855619fe48bc9e5b4f2beb683cb6/ (stored 0%)\n",
            "  adding: content/mlruns/1/535c855619fe48bc9e5b4f2beb683cb6/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/1/535c855619fe48bc9e5b4f2beb683cb6/artifacts/npy/ (stored 0%)\n",
            "  adding: content/mlruns/1/535c855619fe48bc9e5b4f2beb683cb6/artifacts/npy/test_preds_xgb.npy (deflated 9%)\n",
            "  adding: content/mlruns/1/535c855619fe48bc9e5b4f2beb683cb6/artifacts/npy/oof_xgb.npy (deflated 48%)\n",
            "  adding: content/mlruns/1/4a5a151107354381890b7a5f582a8c4a/ (stored 0%)\n",
            "  adding: content/mlruns/1/4a5a151107354381890b7a5f582a8c4a/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/1/4a5a151107354381890b7a5f582a8c4a/artifacts/npy/ (stored 0%)\n",
            "  adding: content/mlruns/1/4a5a151107354381890b7a5f582a8c4a/artifacts/npy/oof_stacked.npy (deflated 75%)\n",
            "  adding: content/mlruns/1/4a5a151107354381890b7a5f582a8c4a/artifacts/npy/test_preds_stacked.npy (deflated 76%)\n",
            "  adding: content/mlruns/1/10ec9ac61f3b484c92953673a40cb830/ (stored 0%)\n",
            "  adding: content/mlruns/1/10ec9ac61f3b484c92953673a40cb830/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/1/10ec9ac61f3b484c92953673a40cb830/artifacts/npy/ (stored 0%)\n",
            "  adding: content/mlruns/1/10ec9ac61f3b484c92953673a40cb830/artifacts/npy/test_preds_lgb.npy (deflated 6%)\n",
            "  adding: content/mlruns/1/10ec9ac61f3b484c92953673a40cb830/artifacts/npy/oof_lgb.npy (deflated 6%)\n",
            "  adding: content/mlruns/1/e298560fa2e945cdbd396b1fcc6e243a/ (stored 0%)\n",
            "  adding: content/mlruns/1/e298560fa2e945cdbd396b1fcc6e243a/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/1/e298560fa2e945cdbd396b1fcc6e243a/artifacts/npy/ (stored 0%)\n",
            "  adding: content/mlruns/1/e298560fa2e945cdbd396b1fcc6e243a/artifacts/npy/oof_blend.npy (deflated 6%)\n",
            "  adding: content/mlruns/1/e298560fa2e945cdbd396b1fcc6e243a/artifacts/npy/test_preds_blend.npy (deflated 6%)\n",
            "  adding: content/mlruns/1/5446fd3dbd5d432487235c5785914cfb/ (stored 0%)\n",
            "  adding: content/mlruns/1/5446fd3dbd5d432487235c5785914cfb/artifacts/ (stored 0%)\n",
            "  adding: content/mlruns/1/5446fd3dbd5d432487235c5785914cfb/artifacts/npy/ (stored 0%)\n",
            "  adding: content/mlruns/1/5446fd3dbd5d432487235c5785914cfb/artifacts/npy/oof_blend.npy (deflated 6%)\n",
            "  adding: content/mlruns/1/5446fd3dbd5d432487235c5785914cfb/artifacts/npy/test_preds_blend.npy (deflated 6%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c14e8cb3-58a9-4167-9375-7501c323b65a\", \"file.zip\", 25747510)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a zip file from folder you want to download\n",
        "!zip -r /content/file1.zip /content/npy_results\n",
        "\n",
        "# download file recently created\n",
        "from google.colab import files\n",
        "files.download(\"/content/file1.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "xBQMx7q8ZDQV",
        "outputId": "cffb1694-aab4-4d01-889b-7bc5f3bc3a28"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/npy_results/ (stored 0%)\n",
            "updating: content/npy_results/test_preds_lgb.npy (deflated 6%)\n",
            "updating: content/npy_results/oof_stacked.npy (deflated 75%)\n",
            "updating: content/npy_results/test_preds_stacked.npy (deflated 76%)\n",
            "updating: content/npy_results/oof_lgb.npy (deflated 6%)\n",
            "updating: content/npy_results/test_preds_xgb.npy (deflated 9%)\n",
            "updating: content/npy_results/oof_blend.npy (deflated 6%)\n",
            "updating: content/npy_results/oof_xgb.npy (deflated 48%)\n",
            "updating: content/npy_results/test_preds_blend.npy (deflated 6%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_84341280-3630-4462-80c1-bc2f30404749\", \"file1.zip\", 18959060)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}